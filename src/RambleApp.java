import java.io.File;
import java.io.FileNotFoundException;
import java.util.ArrayList;
import java.util.List;
import java.util.Scanner;

/**
 * The RambleApp class is an application that generates text based on a given file
 * using a UnigramWordPredictor. The text is generated by predicting the next word
 * in a sequence based on training data obtained from the specified file.
 */
public class RambleApp {

    private final Tokenizer tokenizer;
    private final UnigramWordPredictor predictor;
    private final Scanner inputScanner;

    /**
     * Initializes the RambleApp with the specified dependencies.
     * 
     * @param tokenizer the tokenizer used to process the input text
     * @param predictor the UnigramWordPredictor used to generate predictions
     * @param inputScanner the scanner for reading user input
     */
    public RambleApp(Tokenizer tokenizer, UnigramWordPredictor predictor, Scanner inputScanner) {
        this.tokenizer = tokenizer;
        this.predictor = predictor;
        this.inputScanner = inputScanner;
    }

    /**
     * The main workflow of the application. It prompts the user for a filename
     * and the number of words to generate, trains the predictor using the text
     * from the specified file, and generates text based on the training data.
     */
    public void run() {
        String filename = promptForFilename();
        int numWords = promptForNumberOfWords();

        if (!trainPredictor(filename)) {
            System.out.println("Failed to train the predictor. Exiting.");
            return;
        }

        generateText(numWords, filename);
    }

    /**
     * Prompts the user to enter the filename of the text file to use for training.
     * 
     * @return the filename entered by the user
     */
    private String promptForFilename() {
        System.out.print("Enter the filename: ");
        return inputScanner.nextLine();
    }

    /**
     * Prompts the user to enter the number of words to generate.
     * 
     * @return the number of words specified by the user
     */
    private int promptForNumberOfWords() {
        System.out.print("Enter the number of words to generate: ");
        int numWords = inputScanner.nextInt();
        inputScanner.nextLine(); // Consume the newline
        return numWords;
    }

    /**
     * Trains the UnigramWordPredictor using the specified file.
     * The file's contents are read and tokenized to prepare the predictor
     * for generating text.
     * 
     * @param filename the name of the file to use for training
     * @return true if training was successful, false if the file could not be found
     */
    private boolean trainPredictor(String filename) {
        File file = new File(filename);
        try (Scanner fileScanner = new Scanner(file)) {
            predictor.train(fileScanner);
            return true;
        } catch (FileNotFoundException e) {
            System.out.println("File not found: " + filename);
            return false;
        }
    }

    /**
     * Generates the specified number of words of text based on the training data.
     * The generation starts with the first word in the file, and subsequent words
     * are predicted using the UnigramWordPredictor. If the predictor fails to
     * generate a word, an informative message is displayed.
     * 
     * @param numWords the number of words to generate
     * @param filename the name of the file used for training
     */
    private void generateText(int numWords, String filename) {
        List<String> tokens = getTokensFromFile(filename);
        if (tokens == null) {
            System.out.println("No tokens returned from tokenizer!");
            System.out.println("This is probably because you haven't implemented it yet");
            System.out.println("Begin with Wave 1 in the instructions, and implement LowercaseSentenceTokenizer");
            System.out.println("If you have implemented it, there's a bug in your code where it's returning null for the tokens.");
            return;
        }
        if (tokens.isEmpty()) {
            System.out.println("The file is empty. No text to generate.");
            return;
        }

        // Start generating text from the first word in the file
        List<String> context = new ArrayList<>();
        context.add(tokens.get(0));
        System.out.print(context.get(0)); // Print the first word

        for (int i = 1; i < numWords; i++) {
            String nextWord = predictor.predictNextWord(context);
            if (nextWord == null) {
                System.out.println("No prediction made from Predictor!");
                System.out.println("This is probably because you haven't implemented it yet");
                System.out.println("Implement it, and come back and try again");
                System.out.println("If you have implemented it, there's a bug in your code where it's returning null for a prediction.");
                break;
            }
            System.out.print(" " + nextWord);

            // Update the context with the next word
            context.add(nextWord);
        }

        System.out.println();
    }

    /**
     * Reads the contents of the specified file and returns a list of tokens
     * generated by the tokenizer. If the file cannot be read, an empty list is returned.
     * 
     * @param filename the name of the file to read
     * @return a list of tokens from the file, or an empty list if the file could not be read
     */
    private List<String> getTokensFromFile(String filename) {
        File file = new File(filename);
        try (Scanner fileScanner = new Scanner(file)) {
            return tokenizer.tokenize(fileScanner);
        } catch (FileNotFoundException e) {
            System.out.println("Failed to read tokens from file.");
            return new ArrayList<>();
        }
    }

    /**
     * The entry point for the application. Creates an instance of RambleApp
     * with the necessary dependencies and runs the main workflow.
     * 
     * @param args command-line arguments (not used)
     */
    public static void main(String[] args) {
        // Create dependencies
        Tokenizer tokenizer = new LowercaseSentenceTokenizer();
        UnigramWordPredictor predictor = new UnigramWordPredictor(tokenizer);
        Scanner inputScanner = new Scanner(System.in);

        RambleApp app = new RambleApp(tokenizer, predictor, inputScanner);
        app.run();
    }
}
